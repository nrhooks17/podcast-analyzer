version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    container_name: podcast_postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-podcast_analyzer}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Zookeeper (required for Kafka)
  # NOTE: This is not secured for production use
  # In production, proper SASL/SSL authentication would be required
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: podcast_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zk_data:/var/lib/zookeeper/data

  # Apache Kafka
  # NOTE: This is not secured for production use
  # In production, proper SASL/SSL authentication would be required
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: podcast_kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: podcast_backend
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-podcast_analyzer}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      STORAGE_PATH: /app/storage/transcripts
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
    volumes:
      - transcript_storage:/app/storage/transcripts
      # Development volume for hot reloading (remove for production)
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy

  # Kafka Worker (same backend image, different entrypoint)
  kafka-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: podcast_kafka_worker
    command: ["python", "-m", "app.workers.analysis_worker"]
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-podcast_analyzer}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      SERPER_API_KEY: ${SERPER_API_KEY}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      STORAGE_PATH: /app/storage/transcripts
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    volumes:
      - transcript_storage:/app/storage/transcripts
      # Development volume for hot reloading (remove for production)
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: podcast_frontend
    environment:
      REACT_APP_API_BASE_URL: ${REACT_APP_API_BASE_URL:-http://localhost:8000}
    volumes:
      # Development volume for hot reloading (remove for production)
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  postgres_data:
  zk_data:
  kafka_data:
  # Named volume for transcript storage (simulates S3)
  transcript_storage: